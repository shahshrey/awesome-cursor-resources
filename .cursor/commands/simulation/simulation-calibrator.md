<task name="Simulation Calibrator">

<task_objective>
Calibrate simulation accuracy with systematic validation, bias detection, and continuous improvement. Takes simulation type as input (business, technical, behavioral, or strategic simulation), processes it through calibration frameworks including baseline assessment, bias detection, validation loops, real-time calibration, quality assurance, and improvement roadmap, and generates calibrated simulation with validated accuracy metrics, bias correction reports, continuous improvement systems, and enhanced decision support reliability.
</task_objective>

<detailed_sequence_steps>
# Simulation Calibrator - Detailed Sequence of Steps

## 1. Assess Current Simulation State

1. Define simulation type based on $ARGUMENTS (business, technical, behavioral, strategic simulation).

2. Determine accuracy requirements: mission-critical (95%+), strategic (80-95%), or exploratory (50-70%).

3. Identify validation data including historical outcomes, real-world benchmarks, and expert assessments.

4. Document performance metrics including current accuracy levels and improvement opportunities.

## 2. Execute Baseline Assessment

1. Perform historical validation against known outcomes.

2. Calculate accuracy metrics including error rates and prediction quality.

3. Analyze error patterns to identify systematic biases.

4. Document baseline performance across different scenario types.

## 3. Detect and Analyze Biases

1. Identify cognitive biases in expert inputs and assumptions.

2. Detect data biases from sampling, measurement, or selection issues.

3. Analyze model biases from structural assumptions and simplifications.

4. Develop mitigation strategies for each identified bias type.

## 4. Implement Validation Loops

1. Establish multi-level validation including internal consistency checks.

2. Conduct expert review processes for domain validation.

3. Perform empirical testing against real-world outcomes.

4. Create feedback mechanisms for continuous validation improvement.

## 5. Enable Real-Time Calibration

1. Implement continuous monitoring of simulation performance.

2. Create automated adjustment mechanisms for dynamic calibration.

3. Integrate adaptive learning from new data and outcomes.

4. Establish triggers for recalibration based on performance drift.

## 6. Execute Quality Assurance

1. Perform meta-calibration assessment to evaluate calibration quality.

2. Monitor improvement sustainability over time.

3. Validate calibration effectiveness through independent testing.

4. Document quality assurance processes and results.

## 7. Develop Improvement Roadmap

1. Create systematic enhancement strategies for accuracy improvement.

2. Prioritize improvement initiatives based on impact and feasibility.

3. Establish performance tracking systems for progress monitoring.

4. Define success criteria and target accuracy levels.

## 8. Apply Advanced Features

1. Implement automated bias detection algorithms.

2. Apply machine learning calibration techniques.

3. Enable cross-simulation learning for institutional knowledge.

4. Optimize predictive accuracy through ensemble methods.

## 9. Implement Quality Control

1. Establish independent validation processes separate from calibration.

2. Perform benchmark comparison against industry standards.

3. Create comprehensive documentation for institutional learning.

4. Implement peer review and validation protocols.

## 10. Generate Calibrated Output

1. Deliver calibrated simulation with enhanced accuracy.

2. Provide validated accuracy metrics with confidence intervals.

3. Document bias correction reports showing improvements.

4. Deliver continuous improvement systems and enhanced decision support reliability for ongoing simulation quality management.

</detailed_sequence_steps>

</task>
