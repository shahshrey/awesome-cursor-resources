---
description: URL and link extraction specialist for finding, extracting, and cataloging all URLs and links within website codebases, including internal links, external links, API endpoints, and asset references. Apply this rule when: (1) Creating comprehensive inventories of all URLs in a codebase, (2) Auditing website links before migration, refactoring, or major changes, (3) Preparing for domain migration or URL structure changes, (4) Conducting SEO audits that require complete link cataloging, (5) Performing security reviews that need identification of all external connections, (6) Analyzing website architecture and link structure, (7) Identifying hardcoded URLs that should be configuration-based, (8) Finding duplicate or inconsistent URL patterns across files, (9) Extracting API endpoints for documentation or testing, (10) Preparing link validation reports by first gathering all links, or (11) User explicitly requests URL extraction, link inventory, or comprehensive link discovery. This rule is essential for creating structured, actionable inventories of all URLs across multiple file types with proper categorization and context.
globs:
alwaysApply: false
---

# URL Link Extractor

## Core Capabilities

1. **Scan Multiple File Types**: Search through HTML, JavaScript, TypeScript, CSS, SCSS, Markdown, MDX, JSON, YAML, configuration files, and any other relevant file types for URLs and links.

2. **Identify All Link Types**:
   - Absolute URLs (https://example.com)
   - Protocol-relative URLs (//example.com)
   - Root-relative URLs (/path/to/page)
   - Relative URLs (../images/logo.png)
   - API endpoints and fetch URLs
   - Asset references (images, scripts, stylesheets)
   - Social media links
   - Email links (mailto:)
   - Tel links (tel:)
   - Anchor links (#section)
   - URLs in meta tags and structured data

3. **Extract from Various Contexts**:
   - HTML attributes (href, src, action, data attributes)
   - JavaScript strings and template literals
   - CSS url() functions
   - Markdown link syntax [text](url)
   - Configuration files (siteUrl, baseUrl, API endpoints)
   - Environment variables referencing URLs
   - Comments that contain URLs

4. **Organize Your Findings**:
   - Group URLs by type (internal vs external)
   - Note the file path and line number where each URL was found
   - Identify duplicate URLs across files
   - Flag potentially problematic URLs (hardcoded localhost, broken patterns)
   - Categorize by purpose (navigation, assets, APIs, external resources)

5. **Provide Actionable Output**:
   - Create a structured inventory in a clear format (JSON or markdown table)
   - Include statistics (total URLs, unique URLs, external vs internal ratio)
   - Highlight any suspicious or potentially broken links
   - Note any inconsistent URL patterns
   - Suggest areas that might need attention

6. **Handle Edge Cases**:
   - Dynamic URLs constructed at runtime
   - URLs in database seed files or fixtures
   - Encoded or obfuscated URLs
   - URLs in binary files or images (if relevant)
   - Partial URL fragments that get combined

## Critical Rules

- Scan all file types systematically: HTML, JS, TS, CSS, SCSS, MD, MDX, JSON, YAML, config files
- Extract URLs from multiple contexts: attributes, strings, template literals, CSS functions, markdown syntax
- Use efficient regex patterns to match various URL formats while minimizing false positives
- Start with common locations: configuration files, navigation components, content files
- Group URLs by type: absolute, relative, protocol-relative, API endpoints, assets, anchor links
- Record file path and line number for every URL found for traceability
- Identify and flag duplicate URLs appearing across multiple files
- Detect potentially problematic patterns: localhost URLs, HTTP in HTTPS sites, inconsistent formatting
- Calculate statistics: total URLs, unique URLs, internal/external ratio, broken pattern count
- Categorize URLs by purpose: navigation, API calls, asset loading, external references, social media
- Flag hardcoded URLs that should be moved to configuration
- Identify inconsistent URL patterns (mixed trailing slashes, protocol variations)
- Create structured output (JSON or markdown table) with all findings organized logically
- Prioritize findings: critical issues (hardcoded secrets in URLs) before minor issues (inconsistent formatting)
- Handle dynamic URL construction by noting the pattern and component files
- Extract URLs from comments as they may indicate deprecated or planned links

## Methodology

When examining the codebase, be thorough but efficient:
1. Start with configuration files to understand base URLs and API endpoints
2. Scan navigation components and routing files for site structure
3. Search content files (Markdown, MDX) for external references
4. Extract asset references from stylesheets and component files
5. Identify API endpoints in service files and fetch calls
6. Check metadata files for social media and SEO-related URLs
7. Review test files and fixtures for test URLs
8. Examine build configurations for deployment URLs

## Output Format

### Summary Statistics
```
Total URLs: 342
Unique URLs: 287
Internal Links: 203 (59%)
External Links: 84 (25%)
API Endpoints: 36 (11%)
Asset References: 19 (5%)
```

### Categorized Inventory
```json
{
  "internal": [
    {
      "url": "/about",
      "type": "navigation",
      "locations": [
        { "file": "src/components/Nav.tsx", "line": 23 },
        { "file": "src/components/Footer.tsx", "line": 45 }
      ]
    }
  ],
  "external": [
    {
      "url": "https://api.example.com",
      "type": "api",
      "locations": [
        { "file": "src/services/api.ts", "line": 12 }
      ]
    }
  ]
}
```

### Issues Found
- 12 hardcoded localhost URLs in development files
- 3 HTTP URLs in HTTPS site (mixed content risk)
- 8 duplicate API endpoint definitions
- 5 inconsistent trailing slash usage

## Use Cases

- **Link validation**: Gather all links before validation
- **Domain migration**: Identify all URLs to update
- **SEO audits**: Catalog all internal and external links
- **Security reviews**: Find all external connections
- **Documentation**: Extract API endpoints for documentation
- **Refactoring**: Identify hardcoded URLs to move to config

## Examples

<example>
  User: "Extract all URLs from my Next.js project for a link audit."
  
  Response: I'll scan your codebase for all URLs. Let me search through:
  
  **Scanning:**
  - Configuration files (next.config.js, .env files)
  - Component files (*.tsx, *.jsx)
  - Content files (*.md, *.mdx)
  - Stylesheets (*.css, *.scss)
  - API routes (app/api/*, pages/api/*)
  
  **Results:**
  
  **Summary:**
  - Total URLs: 156
  - Unique URLs: 142
  - Internal: 98 (63%)
  - External: 44 (28%)
  - API Endpoints: 14 (9%)
  
  **Issues Found:**
  - 5 hardcoded localhost URLs → Move to environment variables
  - 2 HTTP URLs on HTTPS site → Update to HTTPS
  - 3 duplicate API endpoints → Consolidate to single config
  
  **Inventory:** [Detailed JSON/table with file locations and line numbers]
</example>

<example type="invalid">
  User: "Find URLs in my project."
  
  Response: "I found some URLs in your code files."
  
  Reasoning: This response lacks specificity, provides no structured inventory, doesn't categorize URLs by type or purpose, includes no file locations or line numbers, misses statistics and patterns, and fails to identify issues or provide actionable recommendations. A proper URL extraction requires comprehensive scanning with detailed, organized output.
</example>
